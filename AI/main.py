# main.py

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing    import List
import numpy as np
import pandas as pd
import asyncio, logging

from aiokafka import AIOKafkaConsumer, AIOKafkaProducer
from sklearn.preprocessing import StandardScaler
from model_loader import sleephony, LABELS               # â† ê¸°ì¡´ ëª¨ë¸Â·ë¼ë²¨ ë¡œë”

# â”€â”€ ë¡œê¹… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(level=logging.INFO, format="%(asctime)s  %(message)s")
logger = logging.getLogger("sleephony")

# â”€â”€ Kafka ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KAFKA_BOOTSTRAP = "k12c208.p.ssafy.io:29092"
REQUEST_TOPIC  = "sleep-stage-raw-request"
RESPONSE_TOPIC = "sleep-stage-raw-response"
GROUP_ID       = "sleepony-fastapi-group"

# â”€â”€ ì‹ í˜¸ ì²˜ë¦¬ íŒŒë¼ë¯¸í„° (20â€¯Hz ê¸°ì¤€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SAMPLING_RATE = 20          # 20â€¯samples / sec
EPOCH_SECONDS = 30          # í•œ ì—í¬í¬ 30â€¯ì´ˆ
STEP_SECONDS  = 15          # 50â€¯% overlap
SEQ_LEN       = 5           # ëª¨ë¸ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´

EPOCH_SIZE = SAMPLING_RATE * EPOCH_SECONDS   # 600
STEP       = SAMPLING_RATE * STEP_SECONDS    # 300

# â”€â”€ FastAPI ì¸ìŠ¤í„´ìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(
    title="Sleephony API",
    version="0.1.0",
    root_path="/ai"          # â†” ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ê²½ë¡œì— ë§ì¶°ë‘” ì˜ˆì‹œ
)

# â”€â”€ Pydantic ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class RawPayload(BaseModel):
    acc_x: List[float]
    acc_y: List[float]
    acc_z: List[float]
    temp:  List[float]
    hr:    List[float]

class RawResponse(BaseModel):
    requestId: str
    labels:    List[str]

# â”€â”€ Kafka í”„ë¡œë“€ì„œ/ì»¨ìŠˆë¨¸ í•¸ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
producer:  AIOKafkaProducer | None = None
consumer:  AIOKafkaConsumer | None = None

# â”€â”€ í—¬ìŠ¤ ì²´í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
def health():
    return {"status": "ok"}

# â”€â”€ ìŠ¤íƒ€íŠ¸ì—… / ì…§ë‹¤ìš´ í›… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.on_event("startup")
async def startup_event():
    global producer, consumer

    producer = AIOKafkaProducer(
        bootstrap_servers=KAFKA_BOOTSTRAP,
        value_serializer=lambda v: v.json().encode("utf-8")
    )
    await producer.start()

    consumer = AIOKafkaConsumer(
        REQUEST_TOPIC,
        bootstrap_servers=KAFKA_BOOTSTRAP,
        group_id=GROUP_ID,
        value_deserializer=lambda b: RawPayload.parse_raw(b)
    )
    await consumer.start()

    asyncio.create_task(process_loop())
    logger.info("âœ… Kafka producer / consumer started")

@app.on_event("shutdown")
async def shutdown_event():
    await consumer.stop()
    await producer.stop()
    logger.info("ğŸ›‘ Kafka connections closed")

# â”€â”€ ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def process_loop():
    """
    1) `sleep-stage-raw-request` í† í”½ì—ì„œ RawPayload ìˆ˜ì‹ 
    2) ì‹œê³„ì—´ â†’ feature â†’ sequence ë³€í™˜ í›„ ëª¨ë¸ ì¶”ë¡ 
    3) ê²°ê³¼ë¥¼ `sleep-stage-raw-response` í† í”½ìœ¼ë¡œ ì†¡ì‹ 
    """
    logger.info("ğŸ”„ Waiting for rawâ€‘sequence messages ...")

    async for msg in consumer:
        payload: RawPayload = msg.value
        headers = {k: v.decode() for k, v in msg.headers}
        req_id  = headers.get("requestId", "unknown")
        user_id = headers.get("userId")           # â† ì—¬ê¸°ì„œ êº¼ë‚´ì•¼ í•©ë‹ˆë‹¤!

        # 0. DataFrame & ê¸¸ì´ ê²€ì‚¬ -------------------------------------------------
        df = pd.DataFrame({
            "ACC_X": payload.acc_x,
            "ACC_Y": payload.acc_y,
            "ACC_Z": payload.acc_z,
            "TEMP":  payload.temp,
            "HR":    payload.hr
        }).dropna()

        if len(df) < EPOCH_SIZE:
            logger.warning(f"[{req_id}] too few samples ({len(df)})")
            await send_error(req_id, f"ìƒ˜í”Œì€ ìµœì†Œ {EPOCH_SIZE}ê°œ í•„ìš”í•©ë‹ˆë‹¤")
            continue

        # 1. ê°€ì†ë„ ë²¡í„° í¬ê¸° ------------------------------------------------------
        df["ACC_MAG"] = np.sqrt(df.ACC_X**2 + df.ACC_Y**2 + df.ACC_Z**2)

        # 2. ìœˆë„ì‰ & í”¼ì²˜ ì¶”ì¶œ ----------------------------------------------------
        feats = []
        for start in range(0, len(df) - EPOCH_SIZE + 1, STEP):
            seg = df.iloc[start : start + EPOCH_SIZE]
            acc = seg.ACC_MAG.values
            tmp = seg.TEMP.values
            hr  = seg.HR.values

            basic = [acc.mean(), acc.std(), tmp.mean(), tmp.std(), hr.mean(), hr.std()]

            ibi   = 60.0 / hr
            rmssd = np.sqrt(np.mean(np.diff(ibi)**2))
            sdnn  = np.std(ibi)

            freqs = np.fft.rfftfreq(len(acc), d=1 / SAMPLING_RATE)
            psd   = np.abs(np.fft.rfft(acc))**2
            delta = psd[(freqs>=0.5) & (freqs<4 )].sum()
            theta = psd[(freqs>=4  ) & (freqs<8 )].sum()
            alpha = psd[(freqs>=8  ) & (freqs<12)].sum()

            feats.append(basic + [rmssd, sdnn, delta, theta, alpha])

        feats = np.asarray(feats, dtype=np.float32)

        if feats.shape[0] < SEQ_LEN:
            await send_error(req_id, f"ì—í¬í¬ ìˆ˜ê°€ ë¶€ì¡±í•´ seq_len={SEQ_LEN} êµ¬ì„± ë¶ˆê°€")
            continue

        # 3. ì •ê·œí™” & ì‹œí€€ìŠ¤ ìƒì„± ---------------------------------------------------
        feats = StandardScaler().fit_transform(feats)
        seqs  = np.stack([feats[i:i+SEQ_LEN] for i in range(len(feats) - SEQ_LEN + 1)])

        # 4. ëª¨ë¸ ì˜ˆì¸¡ --------------------------------------------------------------
        preds   = sleephony.predict(seqs)
        labels  = [LABELS[int(i)] for i in np.argmax(preds, 1)]

        # 5. Kafka ì‘ë‹µ -------------------------------------------------------------
        response = RawResponse(requestId=req_id, labels=labels)
        await producer.send_and_wait(
            RESPONSE_TOPIC,
            response,
            headers=[
                ("requestId", req_id.encode()),
                ("userId",    user_id.encode())    # â† fastapi ì‘ë‹µì—ë„ userId í—¤ë” ì¶”ê°€
                ]
        )
        logger.info(f"[{req_id}] ğŸ sent {len(labels)} labels")

# â”€â”€ ì˜¤ë¥˜ ì‘ë‹µ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def send_error(request_id: str, message: str):
    err_resp = RawResponse(requestId=request_id, labels=[])
    await producer.send_and_wait(
        RESPONSE_TOPIC,
        err_resp,
        headers=[
            ("requestId", request_id.encode()),
            ("error",     message.encode())
        ]
    )
    logger.error(f"[{request_id}] âŒ {message}")
